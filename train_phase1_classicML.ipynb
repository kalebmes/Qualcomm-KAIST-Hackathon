{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c808b4e-6c06-405f-a9ab-3176236d486b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaleb/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/kaleb/miniconda3/lib/python3.10/site-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "from transformers import *\n",
    "import os\n",
    "import sys\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffe3023f-3ac3-4a1a-b100-2151b077d2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/kaleb/Qualcom_comp/data/hackathon_train.csv', encoding='cp949', index_col=0)\n",
    "\n",
    "# split train and test dataframe\n",
    "train_df_list = []\n",
    "test_df_list = []\n",
    "for idx in df['User_ID'].unique():\n",
    "    train_df_list.append(df[df['User_ID']==idx][0:40])\n",
    "    test_df_list.append(df[df['User_ID']==idx][40:])\n",
    "    \n",
    "train_df = pd.concat(train_df_list, ignore_index=True)\n",
    "test_df = pd.concat(test_df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05d35a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'kykim/bert-kor-base'\n",
    "# model_name = 'monologg/kobigbird-bert-base'\n",
    "# model_name = 'beomi/kcbert-base'\n",
    "# model_name = 'skt/kobert-base-v1'\n",
    "model_name = 'snunlp/KR-BERT-char16424' # MAIN EMBEDDING BERT MODEL\n",
    "# model_name = 'klue/bert-base'\n",
    "# model_name = 'klue/roberta-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d18849bd-b6a3-4cf1-b60c-f4bbec19a1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embedding\n",
    "# train_result = torch.load(f'{model_name.replace(\"/\", \"_\")}_train_snu_only_rep.pt')\n",
    "# test_result = torch.load(f'{model_name.replace(\"/\", \"_\")}_test_snu_only_rep.pt')\n",
    "train_result = torch.load(f'/home/kaleb/Qualcom_comp/{model_name.replace(\"/\", \"_\")}_train_embed_regular.pt')[0]\n",
    "test_result = torch.load(f'/home/kaleb/Qualcom_comp/{model_name.replace(\"/\", \"_\")}_test_embed_regular.pt')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "962af7ad-e05d-452c-bc04-8f293bcffbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random(SEED=0):\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, label, label_idx=0):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.label_idx = label_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], torch.tensor(self.label[idx][self.label_idx])\n",
    "    \n",
    "def convert_mbti_to_label(mbti: str):\n",
    "    \"\"\"\n",
    "    :param mbti: string. length=4\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    stand = 'ISTJ'  # [0, 0, 0, 0]\n",
    "    result = []\n",
    "    for i in range(4):\n",
    "        if stand[i] == mbti[i]:\n",
    "            result.append(0)\n",
    "        else:\n",
    "            result.append(1)\n",
    "\n",
    "    return result\n",
    "\n",
    "# def convert_label_to_mbti(num, label_idx):\n",
    "#     stand = 'ISTJ'\n",
    "#     mbti = stand[label_idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93b09c3f-a2a5-4182-87ad-168f09e92d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dl, optimizer, criterion, device=1):\n",
    "    model = model.cuda(device)\n",
    "    model.train()\n",
    "    loss_all, acc_all = 0, 0\n",
    "    \n",
    "    for x, y in dl:\n",
    "        x, y = x.cuda(device), y.cuda(device)\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = (output.argmax(axis=1) == y).sum() / len(y)\n",
    "\n",
    "        loss_all += loss.item()\n",
    "        acc_all += acc.item()\n",
    "\n",
    "\n",
    "    loss = loss_all / len(dl)\n",
    "    acc = acc_all / len(dl)\n",
    "\n",
    "    return loss, acc\n",
    "\n",
    "def valid(model, dl, optimizer=None, criterion=None, device=1):\n",
    "    model = model.cuda(device)\n",
    "    model.eval()\n",
    "    loss_all, acc_all = 0, 0\n",
    "    \n",
    "    output_list = []\n",
    "    for x, y in dl:\n",
    "        x, y = x.cuda(device), y.cuda(device)\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        acc = (output.argmax(axis=1) == y).sum() / len(y)\n",
    "\n",
    "        loss_all += loss.item()\n",
    "        acc_all += acc.item()\n",
    "\n",
    "        output_list.append(output.argmax(dim=1).cpu())\n",
    "        \n",
    "    loss = loss_all / len(dl)\n",
    "    acc = acc_all / len(dl)\n",
    "    \n",
    "    \n",
    "#     # userid accuracy\n",
    "#     result = 0\n",
    "#     a = torch.cat(output_list)\n",
    "#     for uid in test_df['User_ID'].unique():\n",
    "#         idx = test_df[test_df['User_ID']==uid].index\n",
    "#         if a[idx].count_nonzero().item() > len(a[idx])//2:\n",
    "#             label = 1\n",
    "#         else:\n",
    "#             label = 0\n",
    "            \n",
    "#         result += convert_mbti_to_label(test_df[test_df['User_ID']==uid]['MBTI'].unique()[0])[label_idx] == label\n",
    "        \n",
    "    \n",
    "    return loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c897543d-975f-4271-8efc-2f43cfe77bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(model, dl, device=0):\n",
    "    pooled = []\n",
    "    hidden = []\n",
    "    model.cuda(device)\n",
    "    model.eval()\n",
    "    for data in dl:\n",
    "        data = {k:v.cuda(device) for k,v in data.items()}\n",
    "        with torch.no_grad():\n",
    "            output = model(**data, output_hidden_states=True)\n",
    "        p, h = output.pooler_output, output.hidden_states\n",
    "        pooled.append(p) # pooler output\n",
    "        hidden.append(h[-1][:,0,:]) # only [CLS] token embedding \n",
    "    return torch.cat(pooled), torch.cat(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38aaa3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['One_word_answer'] = train_df['Answer'].apply(lambda x: (x.split('>')[0])[x.index('<')+1:])\n",
    "test_df['One_word_answer'] = test_df['Answer'].apply(lambda x: (x.split('>')[0])[x.index('<')+1:])\n",
    "# train_df['One_word_answer'] = train_df['One_word_answer'].astype('category').cat.codes\n",
    "# train_df['One_word_answer'].unique()\n",
    "\n",
    "train_df['One_word_answer'] = train_df['One_word_answer'].apply(lambda x : 1 if x.startswith('중') else (2 if x.startswith('아') or x.startswith('어') else 0))\n",
    "test_df['One_word_answer'] = test_df['One_word_answer'].apply(lambda x : 1 if x.startswith('중') else (2 if x.startswith('아') or x.startswith('어') else 0))\n",
    "\n",
    "train_df['Answer_rep'] = train_df['Answer'].apply(lambda x: x.replace(f\"<{(x.split('>')[0])[x.index('<')+1:]}>\", ''))\n",
    "test_df['Answer_rep'] = test_df['Answer'].apply(lambda x: x.replace(f\"<{(x.split('>')[0])[x.index('<')+1:]}>\", ''))\n",
    "\n",
    "# train_df = pd.get_dummies(train_df, columns=['One_word_answer'], prefix='is')\n",
    "# test_df = pd.get_dummies(test_df, columns=['One_word_answer'], prefix='is')\n",
    "\n",
    "# train_df = pd.get_dummies(train_df, columns=['Age'], prefix='is')\n",
    "# test_df = pd.get_dummies(test_df, columns=['Age'], prefix='is')\n",
    "# train_df['One_word_ans_enc'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b44886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in train_df.columns:\n",
    "#     if col not in test_df.columns:\n",
    "#         test_df[col] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f552c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# added_cols = ['Gender', 'Age'] + [col for col in train_df.columns if col.startswith('is')]\n",
    "\n",
    "added_cols = []\n",
    "nums = 48\n",
    "for _ in range(nums):\n",
    "    added_cols += ['Gender']\n",
    "for _ in range(nums):\n",
    "    added_cols += ['Age']\n",
    "for _ in range(nums//3):\n",
    "    added_cols += [col for col in train_df.columns if col.startswith('is')]\n",
    "\n",
    "\n",
    "col_data = train_df[added_cols].values\n",
    "test_col_data = test_df[added_cols].values\n",
    "\n",
    "# print(col_data[0][0].shape)\n",
    "col_data = col_data.astype(float)\n",
    "test_col_data = test_col_data.astype(float)\n",
    "\n",
    "\n",
    "col_data = torch.tensor(col_data, dtype=torch.float, device='cuda:0')\n",
    "test_col_data = torch.tensor(test_col_data, dtype=torch.float, device='cuda:1')\n",
    "\n",
    "\n",
    "train_result_added = torch.cat([train_result, col_data], dim=1)\n",
    "test_result_added = torch.cat([test_result, test_col_data], dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58255898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9600, 864]), torch.Size([1920, 864]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result_added.shape, test_result_added.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a8c0f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>MBTI</th>\n",
       "      <th>Q_number</th>\n",
       "      <th>Answer</th>\n",
       "      <th>One_word_answer</th>\n",
       "      <th>Answer_rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>INFP</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;아니다&gt; 어릴 때 왕따 당한 경험이 있고 외부 활동을 좋아하지 않기 때문에 소수의...</td>\n",
       "      <td>2</td>\n",
       "      <td>어릴 때 왕따 당한 경험이 있고 외부 활동을 좋아하지 않기 때문에 소수의 친구와만...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>INFP</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;중립&gt;  다양한 관심사를 탐구하진 않지만 대체로 자연과 역사에 관련된 것을 좋아하...</td>\n",
       "      <td>1</td>\n",
       "      <td>다양한 관심사를 탐구하진 않지만 대체로 자연과 역사에 관련된 것을 좋아하며 요즘...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>INFP</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;그렇다&gt; 감정 이입이 잘되어 코미디 영화에서 사람이 울고 있을 때도 울기 때문에 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>감정 이입이 잘되어 코미디 영화에서 사람이 울고 있을 때도 울기 때문에 영화관도 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>INFP</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;중립&gt; 대비책을 세우긴 하는데 세우다가 마는 편입니다. 일의 변수가 생길 수 있고...</td>\n",
       "      <td>1</td>\n",
       "      <td>대비책을 세우긴 하는데 세우다가 마는 편입니다. 일의 변수가 생길 수 있고 변수가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>INFP</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;아니다&gt; 평정심을 유지 못 하는 편입니다. 머릿속은 백지화가 된 상태로 말도 제대...</td>\n",
       "      <td>2</td>\n",
       "      <td>평정심을 유지 못 하는 편입니다. 머릿속은 백지화가 된 상태로 말도 제대로 못합니...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9595</th>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>36</td>\n",
       "      <td>&lt;아니다&gt; 저는 즐거운 파티나 행사로 일주일 피로를 푸는 편이 아닙니다. 이유는 그...</td>\n",
       "      <td>2</td>\n",
       "      <td>저는 즐거운 파티나 행사로 일주일 피로를 푸는 편이 아닙니다. 이유는 그런 식의 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9596</th>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>37</td>\n",
       "      <td>&lt;중립&gt; 저는 미술관 가는 일을 좋아하지 않습니다. 이유는 미술 작품에 관심이 많이...</td>\n",
       "      <td>1</td>\n",
       "      <td>저는 미술관 가는 일을 좋아하지 않습니다. 이유는 미술 작품에 관심이 많이 없기 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9597</th>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>38</td>\n",
       "      <td>&lt;그렇다&gt; 저는 다른 사람의 감정을 이해하기 힘들 때가 많습니다. 이유는 각자의 살...</td>\n",
       "      <td>0</td>\n",
       "      <td>저는 다른 사람의 감정을 이해하기 힘들 때가 많습니다. 이유는 각자의 살아온 환경...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9598</th>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>39</td>\n",
       "      <td>&lt;아니다&gt; 저는 매일 할 일을 계획하지 않습니다. 이유는 매일매일보다는 크게 한 건...</td>\n",
       "      <td>2</td>\n",
       "      <td>저는 매일 할 일을 계획하지 않습니다. 이유는 매일매일보다는 크게 한 건 방식으로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9599</th>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;아니다&gt; 저는 불안함을 많이 느낍니다. 이유는 모든 것이 확실히 되야지만 마음이 ...</td>\n",
       "      <td>2</td>\n",
       "      <td>저는 불안함을 많이 느낍니다. 이유는 모든 것이 확실히 되야지만 마음이 놓이는 성...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9600 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      User_ID  Gender  Age  MBTI  Q_number  \\\n",
       "0           1       1   30  INFP         1   \n",
       "1           1       1   30  INFP         2   \n",
       "2           1       1   30  INFP         3   \n",
       "3           1       1   30  INFP         4   \n",
       "4           1       1   30  INFP         5   \n",
       "...       ...     ...  ...   ...       ...   \n",
       "9595      240       0   40  ISTJ        36   \n",
       "9596      240       0   40  ISTJ        37   \n",
       "9597      240       0   40  ISTJ        38   \n",
       "9598      240       0   40  ISTJ        39   \n",
       "9599      240       0   40  ISTJ        40   \n",
       "\n",
       "                                                 Answer  One_word_answer  \\\n",
       "0     <아니다> 어릴 때 왕따 당한 경험이 있고 외부 활동을 좋아하지 않기 때문에 소수의...                2   \n",
       "1     <중립>  다양한 관심사를 탐구하진 않지만 대체로 자연과 역사에 관련된 것을 좋아하...                1   \n",
       "2     <그렇다> 감정 이입이 잘되어 코미디 영화에서 사람이 울고 있을 때도 울기 때문에 ...                0   \n",
       "3     <중립> 대비책을 세우긴 하는데 세우다가 마는 편입니다. 일의 변수가 생길 수 있고...                1   \n",
       "4     <아니다> 평정심을 유지 못 하는 편입니다. 머릿속은 백지화가 된 상태로 말도 제대...                2   \n",
       "...                                                 ...              ...   \n",
       "9595  <아니다> 저는 즐거운 파티나 행사로 일주일 피로를 푸는 편이 아닙니다. 이유는 그...                2   \n",
       "9596  <중립> 저는 미술관 가는 일을 좋아하지 않습니다. 이유는 미술 작품에 관심이 많이...                1   \n",
       "9597  <그렇다> 저는 다른 사람의 감정을 이해하기 힘들 때가 많습니다. 이유는 각자의 살...                0   \n",
       "9598  <아니다> 저는 매일 할 일을 계획하지 않습니다. 이유는 매일매일보다는 크게 한 건...                2   \n",
       "9599  <아니다> 저는 불안함을 많이 느낍니다. 이유는 모든 것이 확실히 되야지만 마음이 ...                2   \n",
       "\n",
       "                                             Answer_rep  \n",
       "0      어릴 때 왕따 당한 경험이 있고 외부 활동을 좋아하지 않기 때문에 소수의 친구와만...  \n",
       "1       다양한 관심사를 탐구하진 않지만 대체로 자연과 역사에 관련된 것을 좋아하며 요즘...  \n",
       "2      감정 이입이 잘되어 코미디 영화에서 사람이 울고 있을 때도 울기 때문에 영화관도 ...  \n",
       "3      대비책을 세우긴 하는데 세우다가 마는 편입니다. 일의 변수가 생길 수 있고 변수가...  \n",
       "4      평정심을 유지 못 하는 편입니다. 머릿속은 백지화가 된 상태로 말도 제대로 못합니...  \n",
       "...                                                 ...  \n",
       "9595   저는 즐거운 파티나 행사로 일주일 피로를 푸는 편이 아닙니다. 이유는 그런 식의 ...  \n",
       "9596   저는 미술관 가는 일을 좋아하지 않습니다. 이유는 미술 작품에 관심이 많이 없기 ...  \n",
       "9597   저는 다른 사람의 감정을 이해하기 힘들 때가 많습니다. 이유는 각자의 살아온 환경...  \n",
       "9598   저는 매일 할 일을 계획하지 않습니다. 이유는 매일매일보다는 크게 한 건 방식으로...  \n",
       "9599   저는 불안함을 많이 느낍니다. 이유는 모든 것이 확실히 되야지만 마음이 놓이는 성...  \n",
       "\n",
       "[9600 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55b9771c-e8bc-4e10-8b11-5ee146b2b179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaleb/miniconda3/lib/python3.10/site-packages/cudf/utils/utils.py:218: FutureWarning: The cudf.set_allocator function is deprecated and will be removed in a future release. Please use rmm.reinitialize (https://docs.rapids.ai/api/rmm/stable/api.html#rmm.reinitialize) instead. Note that `cudf.set_allocator(allocator=\"managed\")` is equivalent to `rmm.reinitialize(managed_memory=True)`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from thundersvm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import preprocessing\n",
    "import joblib\n",
    "# import AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from cuml import *\n",
    "import cudf\n",
    "\n",
    "gpu_id = 0\n",
    "cudf.set_allocator(\"managed\")\n",
    "# cudf.cuda.select_device(gpu_id)\n",
    "\n",
    "train_data = train_result_added\n",
    "test_data = test_result_added\n",
    "\n",
    "# data_merged = torch.cat([train_data, test_data], dim=0)\n",
    "\n",
    "\n",
    "def main(label_idx, train_data_func, test_data_func, model):\n",
    "    # dataset / dataloader\n",
    "    # quantile_transformer = preprocessing.QuantileTransformer(n_quantiles = 100)#, output_distribution = 'uniform')\n",
    "    \n",
    "    train_data = train_data_func.detach().cpu().numpy()\n",
    "    # train_data = quantile_transformer.fit_transform(train_data)\n",
    "    # joblib.dump(quantile_transformer, f'./quantile_transformer_{label_idx}.pkl')\n",
    "    \n",
    "    \n",
    "    train_label = train_df['MBTI'].map(convert_mbti_to_label)\n",
    "    train_label = np.array([train_lab[label_idx] for train_lab in train_label])\n",
    "    \n",
    "    test_data = test_data_func.detach().cpu().numpy()\n",
    "    # test_data = quantile_transformer.transform(test_data)\n",
    "    test_label = test_df['MBTI'].map(convert_mbti_to_label)\n",
    "    test_label = np.array([test_lab[label_idx] for test_lab in test_label])\n",
    "    \n",
    "    \n",
    "    data_merged = np.concatenate([train_data, test_data], axis=0)\n",
    "    label_merged = np.concatenate([train_label, test_label], axis=0)    \n",
    "    \n",
    "    \n",
    "    model.fit(train_data, train_label)\n",
    "    # model.fit(data_merged, label_merged) # we just uncomment this line to train on all data\n",
    "    # pred_train = model.predict(train_data)\n",
    "    \n",
    "    # MAIN\n",
    "    # prediction = model.predict(test_data)\n",
    "    # best_accuracy = accuracy_score(test_label, prediction)\n",
    "    \n",
    "    \n",
    "    prediction = model.predict_proba(test_data)\n",
    "    best_roc = roc_auc_score(test_label, prediction[:, 1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return best_roc, model#, pred_train, prediction, train_label, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5198f7f7-89b5-43a1-8184-4eb34919cb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy for IE: 0.7586566840277778\n",
      "Best accuracy for SN: 0.6845019531250001\n",
      "Best accuracy for TF: 0.6908170572916666\n",
      "Best accuracy for JP: 0.7098187934027778\n",
      "avg is  0.7109486219618055\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pickle\n",
    "MBTI = ['IE', 'SN', 'TF', 'JP']\n",
    "set_random(42)\n",
    "best_accuracies = {}\n",
    "models = list()\n",
    "\n",
    "# pred_train_n = []\n",
    "# pred_test_n = []\n",
    "\n",
    "\n",
    "model = SVC(kernel='rbf', C=1, gamma=0.085, probability=True)\n",
    "    \n",
    "# model = DecisionTreeClassifier(max_depth=10)\n",
    "# model = RandomForestClassifier(max_depth=10, n_estimators=100, random_state=0)\n",
    "# model = XGBClassifier(max_depth=10, n_estimators=100, random_state=0)\n",
    "# model = LogisticRegression(C = 0.1)\n",
    "# model = GradientBoostingClassifier(max_depth=10, n_estimators=100, random_state=0)\n",
    "# model = KNeighborsClassifier(n_neighbors=5)\n",
    "for i in range(4):\n",
    "    \n",
    "    result, model = main(i, train_data, test_data, model)\n",
    "    best_accuracies[MBTI[i]] = result\n",
    "    models.append(model)\n",
    "    # print(f'Best accuracy for {C} and {gamma} {MBTI[i]}: {result}')\n",
    "        \n",
    "    # result, model = main(i, train_data, test_data)\n",
    "    # best_accuracies[MBTI[i]] = result\n",
    "    # models.append(model)\n",
    "    print(f'Best accuracy for {MBTI[i]}: {result}')\n",
    "\n",
    "\n",
    "\n",
    "avg = np.mean(list(best_accuracies.values()))\n",
    "print('avg is ', avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ac9d797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy for each MBTI:\n",
      " {'IE': 0.7586566840277778, 'SN': 0.6845019531250001, 'TF': 0.6908170572916666, 'JP': 0.7098187934027778}\n",
      "Final average accuracy on validation dataset: 0.7109486219618055\n"
     ]
    }
   ],
   "source": [
    "print(f'Best accuracy for each MBTI:\\n {best_accuracies}')\n",
    "# final average accuracy of the 4 models\n",
    "final_average_accuracy = sum(best_accuracies.values()) / len(best_accuracies)\n",
    "print(f'Final average accuracy on validation dataset: {final_average_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd38debc8939d20aef59f39ab68609c3347ed5c96fcef172f14e92af6cc98870"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
