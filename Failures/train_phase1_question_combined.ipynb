{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/qia/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "from transformers import *\n",
    "import os\n",
    "import sys\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/hackathon_train.csv', encoding='cp949', index_col=0)\n",
    "\n",
    "# split train and test dataframe\n",
    "train_df_list = []\n",
    "test_df_list = []\n",
    "for idx in df['User_ID'].unique():\n",
    "    train_df_list.append(df[df['User_ID']==idx][0:40])\n",
    "    test_df_list.append(df[df['User_ID']==idx][40:])\n",
    "    \n",
    "train_df = pd.concat(train_df_list, ignore_index=True)\n",
    "test_df = pd.concat(test_df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embeddings\n",
    "train_question_embeddings = torch.load('./embedded/train_result_question.pt')\n",
    "train_answer_embeddings = torch.load('./embedded/train_result_answer.pt')\n",
    "test_question_embeddings = torch.load('./embedded/test_result_question.pt')\n",
    "test_answer_embeddings = torch.load('./embedded/test_result_answer.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the question and the answer embeddings for both train and test\n",
    "combined_train_embeddings = torch.cat([train_question_embeddings[0], train_answer_embeddings[0]], dim=1)\n",
    "combined_test_embeddings = torch.cat([test_question_embeddings[0], test_answer_embeddings[0]], dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9600, 1536])\n",
      "torch.Size([1920, 1536])\n"
     ]
    }
   ],
   "source": [
    "# print the shape of the combined embeddings\n",
    "print(combined_train_embeddings.shape)\n",
    "print(combined_test_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random(SEED=0):\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, label, label_idx=0):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.label_idx = label_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], torch.tensor(self.label[idx][self.label_idx])\n",
    "    \n",
    "def convert_mbti_to_label(mbti: str):\n",
    "    \"\"\"\n",
    "    :param mbti: string. length=4\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    stand = 'ISTJ'  # [0, 0, 0, 0]\n",
    "    result = []\n",
    "    for i in range(4):\n",
    "        if stand[i] == mbti[i]:\n",
    "            result.append(0)\n",
    "        else:\n",
    "            result.append(1)\n",
    "\n",
    "    return result\n",
    "\n",
    "# def convert_label_to_mbti(num, label_idx):\n",
    "#     stand = 'ISTJ'\n",
    "#     mbti = stand[label_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dl, optimizer, criterion, device=1):\n",
    "    model = model.cuda(device)\n",
    "    model.train()\n",
    "    loss_all, acc_all = 0, 0\n",
    "    \n",
    "    for x, y in dl:\n",
    "        x, y = x.cuda(device), y.cuda(device)\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = (output.argmax(axis=1) == y).sum() / len(y)\n",
    "\n",
    "        loss_all += loss.item()\n",
    "        acc_all += acc.item()\n",
    "\n",
    "\n",
    "    loss = loss_all / len(dl)\n",
    "    acc = acc_all / len(dl)\n",
    "\n",
    "    return loss, acc\n",
    "\n",
    "def valid(model, dl, optimizer=None, criterion=None, device=1):\n",
    "    model = model.cuda(device)\n",
    "    model.eval()\n",
    "    loss_all, acc_all = 0, 0\n",
    "    \n",
    "    output_list = []\n",
    "    for x, y in dl:\n",
    "        x, y = x.cuda(device), y.cuda(device)\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        acc = (output.argmax(axis=1) == y).sum() / len(y)\n",
    "\n",
    "        loss_all += loss.item()\n",
    "        acc_all += acc.item()\n",
    "\n",
    "        output_list.append(output.argmax(dim=1).cpu())\n",
    "        \n",
    "    loss = loss_all / len(dl)\n",
    "    acc = acc_all / len(dl)\n",
    "    \n",
    "    \n",
    "#     # userid accuracy\n",
    "#     result = 0\n",
    "#     a = torch.cat(output_list)\n",
    "#     for uid in test_df['User_ID'].unique():\n",
    "#         idx = test_df[test_df['User_ID']==uid].index\n",
    "#         if a[idx].count_nonzero().item() > len(a[idx])//2:\n",
    "#             label = 1\n",
    "#         else:\n",
    "#             label = 0\n",
    "            \n",
    "#         result += convert_mbti_to_label(test_df[test_df['User_ID']==uid]['MBTI'].unique()[0])[label_idx] == label\n",
    "        \n",
    "    \n",
    "    return loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(model, dl, device=0):\n",
    "    pooled = []\n",
    "    hidden = []\n",
    "    model.cuda(device)\n",
    "    model.eval()\n",
    "    for data in dl:\n",
    "        data = {k:v.cuda(device) for k,v in data.items()}\n",
    "        with torch.no_grad():\n",
    "            output = model(**data, output_hidden_states=True)\n",
    "        p, h = output.pooler_output, output.hidden_states\n",
    "        pooled.append(p) # pooler output\n",
    "        hidden.append(h[-1][:,0,:]) # only [CLS] token embedding \n",
    "    return torch.cat(pooled), torch.cat(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(label_idx=0, device=1, name='test', epochs=500):\n",
    "    \n",
    "    model = nn.Sequential(nn.Linear(768*2, 50),\n",
    "                              nn.ReLU(),\n",
    "                              nn.Linear(50, 2))\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "        \n",
    "    # dataset / dataloader\n",
    "    train_data = combined_train_embeddings # pooled_output of question and answer embeddings\n",
    "    train_label = train_df['MBTI'].map(convert_mbti_to_label)\n",
    "    \n",
    "    test_data = combined_test_embeddings\n",
    "    test_label = test_df['MBTI'].map(convert_mbti_to_label)\n",
    "    \n",
    "    train_ds = MyDataset(train_data, train_label, label_idx)\n",
    "    test_ds = MyDataset(test_data, test_label, label_idx)\n",
    "\n",
    "    train_dl = DataLoader(train_ds, batch_size=1024, shuffle=True)\n",
    "    test_dl = DataLoader(test_ds, batch_size=1024, shuffle=False)\n",
    "\n",
    "    # train\n",
    "    train_final = []\n",
    "    val_final = []\n",
    "    \n",
    "    save_dir = f'./ckpt/{name}'\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train_loss, train_acc = train(model, train_dl, optimizer, criterion, device=0)\n",
    "        # validation\n",
    "        val_loss, val_acc = valid(model, test_dl, criterion=criterion, device=1)\n",
    "\n",
    "        writer.add_scalar('Loss/Train', train_loss, epoch)\n",
    "        writer.add_scalar('Acc/Train', train_acc, epoch)\n",
    "#         wandb.log({'train_loss': train_loss, 'train_acc': train_acc, 'epoch': epoch})\n",
    "        writer.add_scalar('Loss/Test', val_loss, epoch)\n",
    "        writer.add_scalar('Acc/Test', val_acc, epoch)\n",
    "#         writer.add_scalar('Acc/userid', acc, epoch)\n",
    "#         wandb.log({'val_loss': val_loss, 'val_acc': val_acc, 'epoch': epoch})\n",
    "\n",
    "        train_final.append([train_loss, train_acc])\n",
    "        val_final.append([val_loss, val_acc])\n",
    "        \n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "                print(f\"Epoch {epoch}/{epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "                torch.save(model, f\"{save_dir}/epoch_{epoch}.pt\")\n",
    "\n",
    "    return train_final, val_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/500 | Train Loss: 0.6814 | Train Acc: 0.5614 | Val Loss: 0.7020 | Val Acc: 0.4951\n",
      "Epoch 100/500 | Train Loss: 0.6820 | Train Acc: 0.5586 | Val Loss: 0.7122 | Val Acc: 0.5001\n",
      "Epoch 150/500 | Train Loss: 0.6776 | Train Acc: 0.5750 | Val Loss: 0.7041 | Val Acc: 0.5023\n",
      "Epoch 200/500 | Train Loss: 0.6774 | Train Acc: 0.5740 | Val Loss: 0.7052 | Val Acc: 0.5072\n",
      "Epoch 250/500 | Train Loss: 0.6749 | Train Acc: 0.5781 | Val Loss: 0.7064 | Val Acc: 0.5046\n",
      "Epoch 300/500 | Train Loss: 0.6743 | Train Acc: 0.5777 | Val Loss: 0.7070 | Val Acc: 0.5035\n",
      "Epoch 350/500 | Train Loss: 0.6715 | Train Acc: 0.5869 | Val Loss: 0.7071 | Val Acc: 0.5092\n",
      "Epoch 400/500 | Train Loss: 0.6722 | Train Acc: 0.5818 | Val Loss: 0.7117 | Val Acc: 0.5005\n",
      "Epoch 450/500 | Train Loss: 0.6683 | Train Acc: 0.5921 | Val Loss: 0.7086 | Val Acc: 0.5151\n",
      "Epoch 500/500 | Train Loss: 0.6682 | Train Acc: 0.5905 | Val Loss: 0.7082 | Val Acc: 0.5052\n",
      "Epoch 50/500 | Train Loss: 0.6825 | Train Acc: 0.5632 | Val Loss: 0.7044 | Val Acc: 0.5030\n",
      "Epoch 100/500 | Train Loss: 0.6810 | Train Acc: 0.5589 | Val Loss: 0.7079 | Val Acc: 0.4935\n",
      "Epoch 150/500 | Train Loss: 0.6775 | Train Acc: 0.5636 | Val Loss: 0.7092 | Val Acc: 0.4962\n",
      "Epoch 200/500 | Train Loss: 0.6738 | Train Acc: 0.5781 | Val Loss: 0.7141 | Val Acc: 0.4742\n",
      "Epoch 250/500 | Train Loss: 0.6721 | Train Acc: 0.5793 | Val Loss: 0.7138 | Val Acc: 0.4802\n",
      "Epoch 300/500 | Train Loss: 0.6711 | Train Acc: 0.5797 | Val Loss: 0.7145 | Val Acc: 0.4849\n",
      "Epoch 350/500 | Train Loss: 0.6698 | Train Acc: 0.5856 | Val Loss: 0.7153 | Val Acc: 0.4888\n",
      "Epoch 400/500 | Train Loss: 0.6728 | Train Acc: 0.5801 | Val Loss: 0.7180 | Val Acc: 0.4888\n",
      "Epoch 450/500 | Train Loss: 0.6694 | Train Acc: 0.5850 | Val Loss: 0.7199 | Val Acc: 0.4815\n",
      "Epoch 500/500 | Train Loss: 0.6663 | Train Acc: 0.5895 | Val Loss: 0.7186 | Val Acc: 0.4877\n",
      "Epoch 50/500 | Train Loss: 0.6838 | Train Acc: 0.5515 | Val Loss: 0.7012 | Val Acc: 0.4993\n",
      "Epoch 100/500 | Train Loss: 0.6803 | Train Acc: 0.5604 | Val Loss: 0.6991 | Val Acc: 0.4974\n",
      "Epoch 150/500 | Train Loss: 0.6777 | Train Acc: 0.5730 | Val Loss: 0.7019 | Val Acc: 0.4979\n",
      "Epoch 200/500 | Train Loss: 0.6753 | Train Acc: 0.5790 | Val Loss: 0.7039 | Val Acc: 0.5024\n",
      "Epoch 250/500 | Train Loss: 0.6754 | Train Acc: 0.5700 | Val Loss: 0.7026 | Val Acc: 0.5072\n",
      "Epoch 300/500 | Train Loss: 0.6725 | Train Acc: 0.5855 | Val Loss: 0.7043 | Val Acc: 0.5015\n",
      "Epoch 350/500 | Train Loss: 0.6744 | Train Acc: 0.5763 | Val Loss: 0.7100 | Val Acc: 0.5003\n",
      "Epoch 400/500 | Train Loss: 0.6719 | Train Acc: 0.5838 | Val Loss: 0.7041 | Val Acc: 0.4972\n",
      "Epoch 450/500 | Train Loss: 0.6719 | Train Acc: 0.5789 | Val Loss: 0.7058 | Val Acc: 0.5042\n",
      "Epoch 500/500 | Train Loss: 0.6712 | Train Acc: 0.5828 | Val Loss: 0.7092 | Val Acc: 0.5080\n",
      "Epoch 50/500 | Train Loss: 0.6828 | Train Acc: 0.5557 | Val Loss: 0.6999 | Val Acc: 0.4991\n",
      "Epoch 100/500 | Train Loss: 0.6799 | Train Acc: 0.5609 | Val Loss: 0.7007 | Val Acc: 0.5042\n",
      "Epoch 150/500 | Train Loss: 0.6794 | Train Acc: 0.5652 | Val Loss: 0.7022 | Val Acc: 0.5075\n",
      "Epoch 200/500 | Train Loss: 0.6753 | Train Acc: 0.5719 | Val Loss: 0.7064 | Val Acc: 0.4856\n",
      "Epoch 250/500 | Train Loss: 0.6731 | Train Acc: 0.5756 | Val Loss: 0.7087 | Val Acc: 0.4909\n",
      "Epoch 300/500 | Train Loss: 0.6726 | Train Acc: 0.5752 | Val Loss: 0.7085 | Val Acc: 0.5195\n",
      "Epoch 350/500 | Train Loss: 0.6721 | Train Acc: 0.5766 | Val Loss: 0.7078 | Val Acc: 0.4951\n",
      "Epoch 400/500 | Train Loss: 0.6727 | Train Acc: 0.5766 | Val Loss: 0.7119 | Val Acc: 0.4931\n",
      "Epoch 450/500 | Train Loss: 0.6701 | Train Acc: 0.5791 | Val Loss: 0.7120 | Val Acc: 0.5028\n",
      "Epoch 500/500 | Train Loss: 0.6675 | Train Acc: 0.5877 | Val Loss: 0.7144 | Val Acc: 0.5137\n"
     ]
    }
   ],
   "source": [
    "# Train all\n",
    "test_number = 1\n",
    "MBTI = ['IE', 'SN', 'TF', 'JP']\n",
    "set_random(422)\n",
    "for i in range(4):\n",
    "    writer = SummaryWriter(f'./tensorboard/{test_number}/{MBTI[i]}/')\n",
    "    result = main(i, 7, MBTI[i], 500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16 (default, Mar  2 2023, 03:21:46) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d75ce3a803b94efac4a64ba4b2061b9ff4cdf1cfee60657542f81bc6848bbf9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
